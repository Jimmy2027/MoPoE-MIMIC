{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:40:32 CET] Log file: /Users/Hendrik/Documents/master3/leomed_mimic/mimic/logger/logs/UTC-20210131-074032.log\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mimic\n",
    "from mimic.utils import text as text\n",
    "from mimic.utils.experiment import MimicExperiment\n",
    "from mimic.utils.filehandling import get_config_path\n",
    "from mimic.utils.flags import parser\n",
    "from mimic.utils.flags import update_flags_with_config\n",
    "from dataclasses import dataclass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "FLAGS = parser.parse_args([])\n",
    "\n",
    "config_path = get_config_path(FLAGS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "flags = update_flags_with_config(config_path, testing=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "flags.modality = 'PA'\n",
    "flags.img_size = 256\n",
    "flags.text_encoding = 'word'\n",
    "flags.feature_extractor_img = 'resnet'\n",
    "flags.batch_size = 1\n",
    "flags.dataloader_workers = 0\n",
    "flags.device = device\n",
    "flags.normalization = False\n",
    "flags.len_sequence = 128\n",
    "flags.str_experiment = 'something'\n",
    "flags.alpha_modalities = [flags.div_weight_uniform_content, flags.div_weight_m1_content,\n",
    "                          flags.div_weight_m2_content, flags.div_weight_m3_content]\n",
    "flags.use_clf = False\n",
    "flags.dir_gen_eval_fid = 'fdgb'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:40:41 CET] setting dataset\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-99be8ce54c1c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mexp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMimicExperiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflags\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mexp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot_img_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m256\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m256\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mexp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodalities\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot_img_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m384\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m256\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmods\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodalities\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/master3/leomed_mimic/mimic/utils/experiment.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, flags)\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 55\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     56\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodalities\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtyping\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mModality\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_modalities\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_modalities\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodalities\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/master3/leomed_mimic/mimic/utils/experiment.py\u001B[0m in \u001B[0;36mset_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    109\u001B[0m                 \u001B[0md_eval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMimicTextDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'eval'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m                 \u001B[0md_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMimic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m                 \u001B[0md_eval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMimic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'eval'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0md_train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/master3/leomed_mimic/mimic/dataio/MimicDataset.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, args, str_labels, split, clf_training)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn_labels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr_labels\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgs_pa\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn_img_pa\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgs_lat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn_img_lat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreport_findings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfn_findings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'findings'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m         \u001B[0;31m# need to filter out labels that contain the label \"-1\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/mimic/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    583\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    584\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0m_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_zipfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 585\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_legacy_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    586\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/mimic/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_legacy_load\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    770\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdeserialized_storage_keys\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    771\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdeserialized_objects\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 772\u001B[0;31m         \u001B[0mdeserialized_objects\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_from_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moffset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf_should_read_directly\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    773\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0moffset\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    774\u001B[0m             \u001B[0moffset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtell\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "exp = MimicExperiment(flags)\n",
    "exp.plot_img_size = torch.Size([1, flags.img_size, flags.img_size])\n",
    "exp.modalities['text'].plot_img_size = torch.Size([1, flags.img_size+128, flags.img_size])\n",
    "mods = exp.modalities\n",
    "\n",
    "trainloader = DataLoader(exp.dataset_train, batch_size=flags.batch_size,\n",
    "                         shuffle=False,\n",
    "                         num_workers=flags.dataloader_workers, pin_memory=False)\n",
    "\n",
    "nbr_samples = 5\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_datas(which_label:int):\n",
    "    datas = {'PA': [], 'Lateral': [], 'text': []}\n",
    "    texts = []\n",
    "    labels_list = []\n",
    "    for data, labels in trainloader:\n",
    "        if labels[0][which_label].item() == 1:\n",
    "            for mod_key, mod in mods.items():\n",
    "                datas[mod_key].append(mod.plot_data(exp, data[mod_key].squeeze(0)))\n",
    "                if mod_key == 'text':\n",
    "                    texts.append(data[mod_key])\n",
    "                labels_list.append(labels[0].tolist())\n",
    "            if len(datas[mod_key]) == nbr_samples:\n",
    "                return datas, texts, labels_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datas, texts, labels_list = get_datas(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rec = torch.Tensor()\n",
    "\n",
    "for mod in mods:\n",
    "    for idx in range(nbr_samples):\n",
    "        if mod == 'text':\n",
    "            img = datas[f'{mod}'][idx].cpu().unsqueeze(0)\n",
    "        else:\n",
    "\n",
    "            img = datas[f'{mod}'][idx].cpu()\n",
    "            # pad the non text modalities such that they fit in a wider rectangle.\n",
    "            m = nn.ZeroPad2d((64, 64, 0, 0))\n",
    "            img = m(img.squeeze()).unsqueeze(0).unsqueeze(0)\n",
    "        rec = torch.cat((rec, img), 0)\n",
    "\n",
    "fig = mimic.utils.plot.create_fig(f'something.png',\n",
    "                                  img_data=rec,\n",
    "                                  num_img_row=nbr_samples, save_figure=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(fig)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(nbr_samples):\n",
    "    text_sample = text.tensor_to_text(exp, texts[i], one_hot=False)[0]\n",
    "    text_sample = [word for word in text_sample if word != '<pad>']\n",
    "    print(' '.join(text_sample).replace('.', '.\\n'))\n",
    "    print(labels_list[i])\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(datas['PA'][i].squeeze())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(datas['Lateral'][i].squeeze())\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lung Opacity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datas, texts, labels_list = get_datas(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(nbr_samples):\n",
    "    text_sample = text.tensor_to_text(exp, texts[i], one_hot=False)[0]\n",
    "    text_sample = [word for word in text_sample if word != '<pad>']\n",
    "    print(' '.join(text_sample).replace('.', '.\\n'))\n",
    "    print(labels_list[i])\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(datas['PA'][i].squeeze())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(datas['Lateral'][i].squeeze())\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pleural Effusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datas, texts, labels_list = get_datas(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(nbr_samples):\n",
    "    text_sample = text.tensor_to_text(exp, texts[i], one_hot=False)[0]\n",
    "    text_sample = [word for word in text_sample if word != '<pad>']\n",
    "    print(' '.join(text_sample).replace('.', '.\\n'))\n",
    "    print(labels_list[i])\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(datas['PA'][i].squeeze())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(datas['Lateral'][i].squeeze())\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}